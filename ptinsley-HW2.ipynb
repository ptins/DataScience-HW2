{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(a):\n",
    "    return {c: (a==c).nonzero()[0] for c in np.unique(a)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(s):\n",
    "    \n",
    "    # start with zero\n",
    "    result = 0\n",
    "    \n",
    "    # get unique values and counts of set\n",
    "    val, counts = np.unique(s, return_counts=True)\n",
    "    freqs = counts/len(s)\n",
    "    \n",
    "    for p in freqs:\n",
    "        result -= p * np.log2(p)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(y, x):\n",
    "\n",
    "    # start with unconditional entroy of class Y --> H(Y)\n",
    "    result = entropy(y)\n",
    "\n",
    "    # calculate conditional entropy of class Y given feature X_i\n",
    "    val, counts = np.unique(x, return_counts=True)\n",
    "    freqs = counts/len(x)\n",
    "\n",
    "    # 'sum up' weighted average of conditional entropies for X_i taking values x_i --> H(Y|X_i)\n",
    "    for p, v in zip(freqs, val):\n",
    "        result -= p * entropy(y[x == v])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_information(y, x):\n",
    "    \n",
    "    # start with zero\n",
    "    result = 0\n",
    "    \n",
    "    val, counts = np.unique(x, return_counts=True)\n",
    "    freqs = counts/len(x)\n",
    "    \n",
    "    # 'sum up' \n",
    "    for freq in freqs:\n",
    "        result -= freq*np.log2(freq)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(n, d):\n",
    "    return n / d if d else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pure(s):\n",
    "    return len(set(s)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(x, y, crit):\n",
    "    \n",
    "    # If there could be no split, just return the original set\n",
    "    if is_pure(y) or len(y) == 0:\n",
    "        return y\n",
    "\n",
    "    # get attr that yields highest information gain\n",
    "    gain = np.array([information_gain(y, x[col]) for col in x.columns.values])\n",
    "    \n",
    "    if crit=='ID3':\n",
    "        selected_attr = np.argmax(gain)\n",
    "    \n",
    "    elif crit=='C4.5':\n",
    "        split_info = np.array([split_information(y, x[col]) for col in x.columns.values])\n",
    "        gain_ratio = [safe_divide(x,y) for x, y in zip(gain, split_info)]\n",
    "        selected_attr = np.argmax(gain_ratio)\n",
    "    \n",
    "    else:\n",
    "        return 'Invalid splitting criterion...'\n",
    "    \n",
    "    # return y if no gain\n",
    "    if np.all(gain < 1e-6):\n",
    "        return y\n",
    "\n",
    "    # split data using the selected attribute\n",
    "    sets = partition(x[x.columns.values[selected_attr]])\n",
    "\n",
    "    # create dictionary to hold next subsets\n",
    "    result = {}\n",
    "    for k, v in sets.items():\n",
    "        y_subset = y.take(v, axis=0)\n",
    "        x_subset = x.take(v, axis=0)\n",
    "        result[\"%s = %s\" % (x.columns.values[selected_attr], k)] = build_tree(x_subset, y_subset, crit)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(predictions):\n",
    "\n",
    "    # confusion matrix\n",
    "    conf_mat = confusion_matrix(test['Label'], predictions)\n",
    "    print('Confusion Matrix:\\n{}'.format(conf_mat))\n",
    "    \n",
    "    # compute metrics from tn, fp, fn, tp\n",
    "    tn, fp, fn, tp = conf_mat.ravel()\n",
    "    accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2*(recall*precision)/(recall+precision)\n",
    "\n",
    "    print('Accuracy: {}\\nPrecision: {}\\nRecall: {}\\nF1 Score: {}'.format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.txt', sep='\\t', index_col='ID').drop(['Opponent','Date'],axis=1)\n",
    "test  = pd.read_csv('./test.txt', sep='\\t', index_col='ID').drop(['Opponent','Date'],axis=1)\n",
    "X = train.drop('Label', axis=1)\n",
    "y = train.Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees (ID3) - Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Media = 1-NBC': {'Is_Opponent_in_AP25_Preseason = In': ID\n",
      "3      Win\n",
      "7      Win\n",
      "19    Lose\n",
      "23    Lose\n",
      "Name: Label, dtype: object,\n",
      "                   'Is_Opponent_in_AP25_Preseason = Out': {'Is_Home_or_Away = Away': ID\n",
      "11    Win\n",
      "Name: Label, dtype: object,\n",
      "                                                           'Is_Home_or_Away = Home': ID\n",
      "1      Win\n",
      "4      Win\n",
      "6      Win\n",
      "10     Win\n",
      "14     Win\n",
      "15    Lose\n",
      "16    Lose\n",
      "20     Win\n",
      "22     Win\n",
      "Name: Label, dtype: object}},\n",
      " 'Media = 2-ESPN': ID\n",
      "17    Win\n",
      "Name: Label, dtype: object,\n",
      " 'Media = 3-FOX': ID\n",
      "12    Lose\n",
      "Name: Label, dtype: object,\n",
      " 'Media = 4-ABC': {'Is_Opponent_in_AP25_Preseason = In': ID\n",
      "5     Lose\n",
      "24    Lose\n",
      "Name: Label, dtype: object,\n",
      "                   'Is_Opponent_in_AP25_Preseason = Out': ID\n",
      "2      Win\n",
      "8      Win\n",
      "9      Win\n",
      "13    Lose\n",
      "18    Lose\n",
      "Name: Label, dtype: object},\n",
      " 'Media = 5-CBS': ID\n",
      "21    Lose\n",
      "Name: Label, dtype: object}\n"
     ]
    }
   ],
   "source": [
    "tree_id3 = build_tree(X, y, 'ID3')\n",
    "pprint(tree_id3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees (ID3) - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     'Media = 1-NBC': {\n",
    "#         'Is_Opponent_in_AP25_Preseason = In': \n",
    "#             Win (by root node majority)\n",
    "#         'Is_Opponent_in_AP25_Preseason = Out': {\n",
    "#             'Is_Home_or_Away = Away': \n",
    "#                 Win                                               \n",
    "#             'Is_Home_or_Away = Home':\n",
    "#                 Win (by node majority)\n",
    "#         }\n",
    "#     },\n",
    "#     'Media = 2-ESPN': \n",
    "#         Win\n",
    "#     'Media = 3-FOX': \n",
    "#         Lose\n",
    "#     'Media = 4-ABC': {\n",
    "#         'Is_Opponent_in_AP25_Preseason = In': \n",
    "#             Lose (node purity)\n",
    "#         'Is_Opponent_in_AP25_Preseason = Out':\n",
    "#             Win (by node majority)\n",
    "#     },\n",
    "#     'Media = 5-CBS':\n",
    "#         Lose\n",
    "# }\n",
    "\n",
    "predictions_id3 = ['Win','Win','Win','Lose','Win','Win','Win','Win','Win','Lose','Win','Lose']\n",
    "test['Predictions_id3'] = predictions_id3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2 1]\n",
      " [1 8]]\n",
      "Accuracy: 0.8333333333333334\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.8888888888888888\n",
      "F1 Score: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics(test['Predictions_id3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees (C4.5) - Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Is_Opponent_in_AP25_Preseason = In': {'Is_Home_or_Away = Away': ID\n",
      "5     Lose\n",
      "12    Lose\n",
      "24    Lose\n",
      "Name: Label, dtype: object,\n",
      "                                        'Is_Home_or_Away = Home': ID\n",
      "3      Win\n",
      "7      Win\n",
      "19    Lose\n",
      "23    Lose\n",
      "Name: Label, dtype: object},\n",
      " 'Is_Opponent_in_AP25_Preseason = Out': {'Media = 1-NBC': {'Is_Home_or_Away = Away': ID\n",
      "11    Win\n",
      "Name: Label, dtype: object,\n",
      "                                                           'Is_Home_or_Away = Home': ID\n",
      "1      Win\n",
      "4      Win\n",
      "6      Win\n",
      "10     Win\n",
      "14     Win\n",
      "15    Lose\n",
      "16    Lose\n",
      "20     Win\n",
      "22     Win\n",
      "Name: Label, dtype: object},\n",
      "                                         'Media = 2-ESPN': ID\n",
      "17    Win\n",
      "Name: Label, dtype: object,\n",
      "                                         'Media = 4-ABC': ID\n",
      "2      Win\n",
      "8      Win\n",
      "9      Win\n",
      "13    Lose\n",
      "18    Lose\n",
      "Name: Label, dtype: object,\n",
      "                                         'Media = 5-CBS': ID\n",
      "21    Lose\n",
      "Name: Label, dtype: object}}\n"
     ]
    }
   ],
   "source": [
    "tree_c45 = build_tree(X, y, 'C4.5')\n",
    "pprint(tree_c45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     'Is_Opponent_in_AP25_Preseason = In': {\n",
    "#         'Is_Home_or_Away = Away': \n",
    "#             Lose (node purity)\n",
    "#         'Is_Home_or_Away = Home': \n",
    "#             Win (by root node majority)\n",
    "#     },\n",
    "#     'Is_Opponent_in_AP25_Preseason = Out': {\n",
    "#         'Media = 1-NBC': {\n",
    "#             'Is_Home_or_Away = Away': \n",
    "#                 Win                                               \n",
    "#             'Is_Home_or_Away = Home': \n",
    "#                 Win (by node majority)\n",
    "#         },\n",
    "\n",
    "###       'Media = 3-FOX': \n",
    "###           Win (by root node majority)\n",
    "\n",
    "#         'Media = 2-ESPN': \n",
    "#             Win\n",
    "#         'Media = 4-ABC': \n",
    "#             Win (by node majority)\n",
    "#         'Media = 5-CBS':\n",
    "#             Lose\n",
    "#     }\n",
    "# }\n",
    "\n",
    "predictions_c45 = ['Win','Win','Win','Win','Win','Win','Win','Win','Win','Lose','Win','Lose']\n",
    "test['Predictions_c45'] = predictions_c45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2 1]\n",
      " [0 9]]\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.9\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9473684210526316\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics(test['Predictions_c45'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes - Building & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(train, test_row):\n",
    "    \n",
    "    # split up dataset into winning and losing\n",
    "    winning_set, losing_set = train[train['Label']=='Win'], train[train['Label']=='Lose']\n",
    "    \n",
    "    # for overall set, compute p(y=win)\n",
    "    p_y = len(winning_set)/len(train)\n",
    "    \n",
    "    # for winning set, compute conditional probabilities\n",
    "    conditional_probs = []\n",
    "    for col in train.drop('Label', axis=1).columns:\n",
    "        conditional_probs.append(len(winning_set[winning_set[col]==test_row[col]]) / len(winning_set))\n",
    "    \n",
    "    # compute p(y=win|x1,x2,x3) \n",
    "    win = np.prod(np.array(conditional_probs)) * p_y\n",
    "    \n",
    "    # for overall set, compute p(y=lose)\n",
    "    p_not_y = len(losing_set)/len(train)\n",
    "\n",
    "    # for winning set, compute conditional probabilities\n",
    "    conditional_probs = []\n",
    "    for col in train.drop('Label', axis=1).columns:\n",
    "        conditional_probs.append(len(losing_set[losing_set[col]==test_row[col]]) / len(losing_set))\n",
    "    \n",
    "    # compute p(y=lose|x1,x2,x3)\n",
    "    lose = np.prod(np.array(conditional_probs)) * p_not_y\n",
    "         \n",
    "    if win>=lose:\n",
    "        return 'Win'\n",
    "    else:\n",
    "        return 'Lose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_nb = []\n",
    "for i in range(0, len(test)):    \n",
    "    row = test.iloc[i]\n",
    "    x = naive_bayes(train, row)\n",
    "    predictions_nb.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Win',\n",
       " 'Win',\n",
       " 'Win',\n",
       " 'Lose',\n",
       " 'Win',\n",
       " 'Lose',\n",
       " 'Win',\n",
       " 'Win',\n",
       " 'Win',\n",
       " 'Lose',\n",
       " 'Win',\n",
       " 'Lose']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Predictions_nb'] = predictions_nb\n",
    "predictions_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2 1]\n",
      " [2 7]]\n",
      "Accuracy: 0.75\n",
      "Precision: 0.875\n",
      "Recall: 0.7777777777777778\n",
      "F1 Score: 0.823529411764706\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics(test['Predictions_nb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
